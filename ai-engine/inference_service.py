"""
Mule Hunter AI Service - Kaggle IEEE-CIS Production Grade
Features: Auto-Initialization, Absolute Path Resilience, Robust Error Handling
"""

import os
import logging
import torch
import torch.nn.functional as F
import pandas as pd
import numpy as np
from typing import List, Optional
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from torch_geometric.nn import SAGEConv
from torch_geometric.data import Data

# --- LOGGING ---
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(name)s: %(message)s")
logger = logging.getLogger("MuleHunter-Kaggle")

# --- PATH RESOLUTION (Bulletproof for Local/Docker) ---
# os.getcwd() is safer when running as a module or from project root
ROOT_DIR = os.getcwd() 
SHARED_DATA_DIR = os.path.join(ROOT_DIR, "shared-data")

# Absolute paths prevent "File Not Found" errors during different execution contexts
MODEL_PATH = os.path.join(SHARED_DATA_DIR, "mule_model.pth")
DATA_PATH = os.path.join(SHARED_DATA_DIR, "processed_graph.pt")
NODES_CSV_PATH = os.path.join(SHARED_DATA_DIR, "nodes.csv")
EDGES_CSV_PATH = os.path.join(SHARED_DATA_DIR, "transactions.csv")

# --- MODELS & DTOs ---
class MuleSAGE(torch.nn.Module):
    def __init__(self, in_channels: int, hidden_channels: int, out_channels: int):
        super(MuleSAGE, self).__init__()
        self.conv1 = SAGEConv(in_channels, hidden_channels)
        self.conv2 = SAGEConv(hidden_channels, out_channels)

    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = self.conv2(x, edge_index)
        return F.log_softmax(x, dim=1)

class TransactionRequest(BaseModel):
    source_id: int = Field(..., example=13926)
    target_id: int = Field(..., example=315)
    amount: float = Field(..., gt=0)
    timestamp: str = "2025-12-25"

class RiskResponse(BaseModel):
    node_id: int
    risk_score: float
    verdict: str
    model_version: str
    out_degree: int
    risk_ratio: float
    population_size: str
    ja3_detected: bool
    linked_accounts: List[str]
    unsupervised_score: float

# --- GLOBAL STATE ---
model: Optional[MuleSAGE] = None
graph_data: Optional[Data] = None
id_map: dict = {}
reverse_id_map: dict = {}
node_features_df: Optional[pd.DataFrame] = None

# --- CORE LOGIC ---
def load_assets():
    """Bulletproof asset loading with explicit existence checks."""
    global model, graph_data, id_map, reverse_id_map, node_features_df
    
    if not all(os.path.exists(p) for p in [MODEL_PATH, DATA_PATH, NODES_CSV_PATH]):
        logger.error("‚ùå Critical assets missing. Cannot start inference.")
        return False

    try:
        # Load graph and features
        graph_data = torch.load(DATA_PATH, map_location='cpu', weights_only=False)
        node_features_df = pd.read_csv(NODES_CSV_PATH)
        node_features_df['node_id'] = node_features_df['node_id'].astype(str)
        
        # O(1) Lookups for production speed
        id_map = {row['node_id']: idx for idx, row in node_features_df.iterrows()}
        reverse_id_map = {idx: row['node_id'] for idx, row in node_features_df.iterrows()}
        
        # Load GNN Weights (hidden=32 for Kaggle performance)
        model = MuleSAGE(in_channels=5, hidden_channels=32, out_channels=2)
        model.load_state_dict(torch.load(MODEL_PATH, map_location='cpu'))
        model.eval()
        
        logger.info(f"‚úÖ SYSTEM READY: {len(id_map)} entities loaded.")
        return True
    except Exception as e:
        logger.error(f"üí• Failed to load AI: {str(e)}")
        return False

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Ensures AI is ready before accepting traffic."""
    success = load_assets()
    if not success:
        logger.warning("‚ö†Ô∏è Initial load failed. Service starting in limited mode.")
    yield

app = FastAPI(title="Mule Hunter AI - Kaggle Edition", lifespan=lifespan)

# --- GLOBAL EXCEPTION HANDLER ---
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """Catch-all to prevent internal stack trace leaks."""
    logger.error(f"Unhandled error: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={"detail": "Internal Server Error", "code": "AI_ENGINE_CRASH"}
    )

# --- ENDPOINTS ---
@app.get("/health", tags=["System"])
async def health_check():
    return {
        "status": "HEALTHY" if model else "INITIALIZING",
        "nodes_count": len(id_map),
        "model_path": MODEL_PATH
    }

@app.post("/analyze-transaction", response_model=RiskResponse, tags=["Inference"])
def analyze_transaction(tx: TransactionRequest):
    if model is None or graph_data is None:
        raise HTTPException(status_code=503, detail="AI Brain is not loaded.")

    str_id = str(tx.source_id)
    src_idx = id_map.get(str_id)
    tgt_idx = id_map.get(str(tx.target_id), 0)

    # Inductive handling for new nodes (Cold Start)
    if src_idx is not None:
        node_row = node_features_df.iloc[src_idx]
        features = torch.tensor([[
            float(node_row['account_age_days']), 
            float(tx.amount / 1000.0), 
            float(node_row['in_out_ratio']), 
            float(node_row['pagerank']), 
            float(node_row['tx_velocity'] + 1)
        ]], dtype=torch.float)
        out_degree = int(node_row['out_degree']) + 1
        risk_ratio_ui = float(node_row['risk_ratio'])
    else:
        # Default fallback to prevent crash on unknown IDs
        features = torch.tensor([[30.0, tx.amount/1000.0, 1.0, 0.0001, 1.0]], dtype=torch.float)
        src_idx, out_degree, risk_ratio_ui = 0, 1, 1.0

    # Dynamic Graph Injection
    new_edge = torch.tensor([[src_idx], [tgt_idx]], dtype=torch.long)
    temp_edge_index = torch.cat([graph_data.edge_index, new_edge], dim=1)

    with torch.no_grad():
        temp_x = graph_data.x.clone()
        if src_idx < temp_x.size(0):
            temp_x[src_idx] = features[0]
        
        out = model(temp_x, temp_edge_index)
        fraud_risk = float(out[src_idx].exp()[1])

    verdict = "SAFE"
    if fraud_risk > 0.85: verdict = "CRITICAL (MULE)"
    elif fraud_risk > 0.6: verdict = "SUSPICIOUS"

    # Robust Neighbor Lookup
    mask = graph_data.edge_index[0] == src_idx
    neighbors = graph_data.edge_index[1][mask]
    linked = [f"Card_{reverse_id_map.get(i.item(), 'Unknown')}" for i in neighbors[:3]]

    return {
        "node_id": tx.source_id,
        "risk_score": round(fraud_risk, 4),
        "verdict": verdict,
        "model_version": "Kaggle-V2-Bulletproof",
        "out_degree": out_degree,
        "risk_ratio": round(risk_ratio_ui, 2),
        "population_size": f"{len(id_map)} Nodes",
        "ja3_detected": fraud_risk > 0.8,
        "linked_accounts": linked,
        "unsupervised_score": round(abs(fraud_risk - 0.035), 4)
    }